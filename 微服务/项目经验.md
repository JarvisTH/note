## 1.统一的异常处理

1）编写异常处理类，使用@ControllerAdvice

2）使用@ExceptionHandler标注方法可以处理的异常

## 2.JSR303

1)、给Bean添加校验注解: javax. validation, constraints,并定义自己的 message提示

2)、开启校验功能@Valid效果:校验错误以后会有默认的响应;

3)、给校验的bean后紧跟一个 Bindingresult,就可以获取到校验的结果

4）、分组校验：多场景复杂校验

​	1)、 @NotBlank(message = "品牌名必须提交", groups = {AddGroup.class, UpdateGroup.class})给校验注解标注什么情况需要进行校验；

​	2)、@Validated({AddGroup.class})

​	3)、注意，此时没有标注分组的校验注解不起作用，要起作用就必须指定分组。默认在不分组情况@Validated下生效

5)、自定义校验

​	1）编写一个自定义校验注解

​	2）编写一个自定义校验器 ConstraintValidator

​	3）关联自定义校验器和自定义校验注解

*      @Documented
* @Constraint(validatedBy = { ListValueConstraintValidator.class【可以指定多个不同的校验器，适配不同类型的校验】 })
* @Target({ METHOD, FIELD, ANNOTATION_TYPE, CONSTRUCTOR, PARAMETER, TYPE_USE })
* @Retention(RUNTIME)
*      public @interface ListValue {

## 3.feign远程调用接口传入的对象不一致是否🆗

```java
* 1.CouponFeignService.saveSpuBounds(spuBoundTo)
*  1)@RequestBody将spuBoundTo转为json
*  2)找到gulimall-coupon-service服务，给/coupon/spubounds/save发送请求，
*  将上一步转的json放在请求体位置，发送请求；
*  3）对方服务收到请求，请求体里有json数据。
*  save(@RequestBody SpuBoundsEntity spuBounds)将请求体的json转为SpuBoundsEntity
*  只要json数据模型是兼容的，双方服务无需使用同一个to
```

调用流程：

- 构造请求数据，将对象转为json

```java
RequestTemplate template = buildTemplateFromArgs.create(argv);
```

- 发送请求进行执行与解码

```java
executeAndDecode(template, options);
```

- 执行请求会有重试机制

```java
    Retryer retryer = this.retryer.clone();
    while (true) {
      try {
        return executeAndDecode(template, options);
      } catch (RetryableException e) {
        try {
          retryer.continueOrPropagate(e);
        } catch (RetryableException th) {
          Throwable cause = th.getCause();
          if (propagationPolicy == UNWRAP && cause != null) {
            throw cause;
          } else {
            throw th;
          }
        }
        if (logLevel != Logger.Level.NONE) {
          logger.logRetry(metadata.configKey(), logLevel);
        }
        continue;
      }
    }
```

**feign远程调用丢失请求头问题**：

浏览器发送请求，请求头自动了cookie；feign远程调用时创建request，没有带请求头，直接发送给服务。

解决：添加自己的请求拦截器，交给feign调用。

**异步模式下，feign会丢失上下文问题**：

在利用RequestContextHolder获取请求上下文时，因为RequestContextHolder的属性是利用**threadlocal**实现的，在**异步模式下就不在同一个线程下了，无法获取到RequestContextHolder的threadlocal。**

解决：开启子线程前，获取到当前线程的RequestContextHolder属性，把它设置到子线程的RequestContextHolder中。

## 4.整合redis

- 引入redis的starter
- 配置redis的host、端口等信息
- 使用springboot自动配置好的redistemplate操作redis

### 1.产生堆外内存溢出异常 outofDirectmemoryError

- springboot 2使用lettuce操作redis客户端，使用netty网络通信
- lettuce的bug导致netty堆外内存溢出 -Xmx 300m; netty如果没有指定堆外内存，默认-Xmx 300m
- 可以通过-Dio.netty.maxDirectMemory设置，但不能使用-Dio.netty.maxDirectMemory只去调大堆外内存

解决方法：

- 升级lettuce客户端
- 切换jedis客户端

### 2.缓存穿透

查询一个不存在的key，每次都到db中查询。

解决方法，空结果缓存

### 3.缓存雪崩

同一时间大部分缓存失效，高并发打到数据库。

解决方法：设置过期时间（随机值）

### 4.缓存击穿

某一个热点key，在其过期的那一秒，大量请求打到数据库，导致db负载高。

解决方法：加锁，一个请求去查数据库，查到加入缓存（注意这两个操作需要是一个原子操作），其他请求先查缓存

- 本地锁只能锁住当前进程，不能锁住分布式下所有的进程。

- 自实现分布式锁注意死锁问题，设置自动过期时间，**加锁**与设置时间必须是**原子操作**。
- 业务超时导致锁失效被删除，删锁操作删除一个不存在的锁；或者锁失效后被删，其他线程获取锁进入业务操作，删锁操作同时删除了其他线程的锁：即需要确实删除的锁是自己的锁
- 即使确认了自己的锁，在确认锁的网络交互过程中，自己的锁失效了，其他线程进入了，但是仍然执行了删除自己的锁操作，导致误删了其他线程的锁。
- 所以**删锁也必须是原子操作**才行——使用lua脚本

```
if redis.call('get',KEYS[1]) == ARGV[1] then return redis.call('del',KEYS[1]) else return 0 end
```

### 5.引入redisson

- 引入依赖

- 配置redisson

- redis的各种锁使用方便，解决了锁的自动续期，不用担心锁在业务执行期间自动过期删除；加锁的业务只要完成，不会给当前锁续期，即使不手动解锁，默认30s自动解锁。

  指定锁的解锁时间时，一定要大于业务执行时间，因为在锁超时时，不会自动续期，发送给redis执行脚本，进行占锁；没有指定超时时间，就使用30*1000 看门狗默认是时间，只要占锁成功，启动定时任务重新给锁设置过期时间为看门狗默认时间，定时任务延迟看门狗默认时间的三分之一时间执行。实践中仍然要推荐指定时间。

## 5.整合spring cache简化缓存开发

- 引入缓存starter  spring-boot-starter-cache   spring-boot-starter-data-redis

- 写配置文件

  - 自动配置内容：CacheAutoConfiguration 导入 RedisCacheConfiguration，自动配好了缓存管理器RedisCacheManager
  - 简单配置就只需要配置使用redis作为缓存 spring.cache.type=redis

- 注解测试使用缓存：开启缓存功能 @EnableCaching

  - @Cacheable：触发将数据保存到缓存的操作。
  - @CacheEvict：触发将数据从缓存删除的操作
  - @CachePut：不影响方法执行更新缓存
  - @Caching：组合以上多个操作
  - @CacheConfig：在类级别共享缓存的相同配置

- 默认行为

  - 如果缓存中有，方法不用调用；如果缓存没有，调用方法并将结果放入缓存。
  - key是默认自动生成的，缓存名字：：simplekey []
  - 缓存的value的值。默认使用jdk序列号机制，将序列化后的数存到redis
  - 默认ttl时间是-1

  ​    自定义：

  - 指定生成的缓存使用的key： key属性，接收一个spel表达式

  - 指定缓存的数据的存活时间：配置文件中修改ttl  单位ms

  - 指定缓存到redis为json格式： 

    - 原理：CacheAutoConfiguration 导入 RedisCacheConfiguration，自动配好了缓存管理器RedisCacheManager，初始化所有缓存，每个缓存决定使用什么配置，如果RedisCacheConfiguration有就使用，没有就使用默认值；想改缓存配置，只需要给spring容器中放入一个RedisCacheConfiguration即可，会被应用到当前RedisCacheManager管理的所有缓存分区中。

      ```java
      @EnableCaching
      @Configuration
      public class MyCacheConfig {
      
          // 配置文件中的内容没有使用上
          @Bean
          RedisCacheConfiguration redisCacheConfiguration() {
              RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig();
              config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
              config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));
          }
      }
      ```

      这里的问题是配置文件中的redis配置内容没有生效：

    - 原来默认使用的配置文件是如下：

    ```java
    @ConfigurationProperties(prefix = "spring.cache")
    public class CacheProperties {
    ```

    让他生效，需要使用注解绑定：

    ```java
    @EnableCaching
    @Configuration
    @EnableConfigurationProperties(CacheProperties.class)
    public class MyCacheConfig {
        @Bean
        RedisCacheConfiguration redisCacheConfiguration(CacheProperties cacheProperties) {
            RedisCacheConfiguration config = RedisCacheConfiguration.defaultCacheConfig();
            config = config.serializeKeysWith(RedisSerializationContext.SerializationPair.fromSerializer(new StringRedisSerializer()));
            config = config.serializeValuesWith(RedisSerializationContext.SerializationPair.fromSerializer(new GenericJackson2JsonRedisSerializer()));
    
            CacheProperties.Redis redisProperties = cacheProperties.getRedis();
            if (redisProperties.getTimeToLive() != null) {
                config = config.entryTtl(redisProperties.getTimeToLive());
            }
            if (redisProperties.getKeyPrefix() != null) {
                config = config.prefixCacheNameWith(redisProperties.getKeyPrefix());
            }
            if (!redisProperties.isCacheNullValues()) {
                config = config.disableCachingNullValues();
            }
            if (!redisProperties.isUseKeyPrefix()) {
                config = config.disableKeyPrefix();
            }
            return config;
        }
    }
    ```

- spring cache的不足：

  - 读模式：
    - 缓存穿透：查询一个null数据——cache-null-values
    - 缓存击穿：查询一个正好过期的数据。解决方案就是加锁，默认是**无加锁的，spring cache解决方法是cacheable注解中添加sync=true**
    - 缓存雪崩：大量key同时过期。解决：指定过期时间
  - 写模式
    - 读写加锁
    - 引入canal
    - 读多写多，直接查数据库

常规数据（读多写少、即时性、一致性要求不高的数据）——cache负责缓存的读写

特殊数据：特殊设计

## 6.线程池

1) 创建：

   - Executors

   - ThreadPoolExecutor

     ```java
     public ThreadPoolExecutor(
         int corePoolSize,  // 核心线程数（一直存在除非设置了线程超时）。线程池创建好以后准备就绪的线程数量，等待接收异步任务去执行
         int maximumPoolSize,  // 最大线程数量【200】。控制资源
         long keepAliveTime,  // 存活时间。当前正在运行的线程数量大于核心数量时，只要多余的线程空闲大于指定的空闲时间就释放空闲线程。
         TimeUnit unit,	// 时间单位
         BlockingQueue<Runnable> workQueue,	// 阻塞队列，如果任务过多，将多的任务放入队列，空闲任务从队列中取出新任务执行
         ThreadFactory threadFactory,  // 线程创建工程
         RejectedExecutionHandler handler)  // 如果队列满了，按照指定的拒绝策略拒绝执行任务
     ```

     工作顺序：

     1、 线程池创建， 准备好 core 数量的核心线程， 准备接受任务

     2、 新的任务进来， 用 core 准备好的空闲线程执行。

     ​	(1) 、 core 满了， 就将再进来的任务放入阻塞队列中。 空闲的 core 就会自己去阻塞队列获取任务执行

     ​	(2) 、 阻塞队列满了， 就直接开新线程执行， 最大只能开到 max 指定的数量

     ​	(3) 、 max 都执行好了。 Max-core 数量空闲的线程会在 keepAliveTime 指定的时间后自动销毁。 最终保持到 core 大小

     ​	(4) 、 如果线程数开到了 max 的数量， 还有新任务进来， 就会使用 reject 指定的拒绝策略进行处理

     3、 所有的线程创建都是由指定的 factory 创建的。

     注意：

     ```java
     LinkedBlockingQueue  默认Integer 最大值，内存可能不够，一定要限制数量
     ```

     拒绝策略：

     ```
     AbortPolicy：
     CallerRunsPolicy：
     DiscardOldestPolicy：
     DiscardPolicy：
     ```

     

## 7.spring session核心原理

@EnableRedisHttpSession导入RedisHttpSessionConfiguration配置

- 给容器添加了一个组件

  sessionRepository ——》RedisIndexedSessionRepository ——》 redis操作session，增删改查

- SessionRepositoryFilter——》session 存储过滤器，每个请求过来都必须经过filter

  - 创建的时候，自动从容器中获取到sessionRepository 
  - 原始request、response被包装SessionRepositoryRequestWrapper、SessionRepositoryResponseWrapper
  - 之前通过request.getsession获取session
  - 现在wrappedRequest.getsession——》从sessionRepository 中获取。

​             **装饰者模式**。

```java
protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain filterChain)
			throws ServletException, IOException {
		request.setAttribute(SESSION_REPOSITORY_ATTR, this.sessionRepository);

		SessionRepositoryRequestWrapper wrappedRequest = new SessionRepositoryRequestWrapper(request, response);
		SessionRepositoryResponseWrapper wrappedResponse = new SessionRepositoryResponseWrapper(wrappedRequest,
				response);

		try {
			filterChain.doFilter(wrappedRequest, wrappedResponse);
		}
		finally {
			wrappedRequest.commitSession();
		}
	}
```

**spring session解决不了单点登录问题**——对于gulimall.com这一系列子域，他可以做到统一登录，但是引入了旗下其他系统，他们的父域不是gulimall.com，没有办法使用spring session。

## 8.引入RabbitMQ

- 引入amqp场景启动器——RabbitAutoConfiguration自动生效

- 给容器中自动配置了RabbitTemplate、AmqpAdmin、RabbitMessagingTemplate、CachingConnectionFactory

  - 所有属性都是下列类绑定

    ```java
    @ConfigurationProperties(prefix = "spring.rabbitmq")
    public class RabbitProperties
    ```

- @EnableRabbit开启功能

- 配置文件中配置rabbitmq连接信息

- 监听消息：使用@RabbitListener（类+方法）、@RabbitHandler（方法，重载区分不同消息），标注在业务逻辑组件上，组件必须在容器中，方法参数可以写以下类型：

  原生类型Message、使用发送的类型、通道channel

### 1.如何创建exchange、queue、binding

1）使用AmqpAdmin场景

### 2.如何收发消息

RabbitTemplate收发消息。

如果发送的消息是一个对象，会使用序列化机制将对象写出去，对象必须实现序列化接口；发送的序列化消息也可以是json，

### 3.发送者确认

- 服务收到消息就回调

  ```
  publisher-confirm-type: correlated
  ```

  设置确认回调confirmcallback

- 消息正确抵达队列进行回调

  ```
  publisher-returns: true
  template:
        mandatory: true
  ```

  设置确认回调returncallback

### 4.消费者确认——ack机制

保证每个消息被正确消费，broker才可以删除消息；默认自动确认。

问题：收到很多消息，自动回复给服务器，只有一个消息确认了，然后服务器宕机，其他消息丢失。—— 手动确认，不确认消息就不丢失，处于unacked状态，即使服务器宕机，消息不会丢失，重新变为ready状态，下次继续发送。

```
listener:
      simple:
        acknowledge-mode: manual
```

如何签收？

channel可以进行签收。

- basicack
- basicnack
- basicreject



结合发送端确认机制与消费者确认机制可以达到消息100%不丢失。

## 9.@Transactional方法说明

同一个service内，a调用了b、c方法，三个方法均有事务，b、c做任何设置都没有用，都是和a共用一个事务。因为事务是用代理对象来做的，直接调用service自身的b、c方法，相当于跳过了代理，本质上就是调用b、c的代码，不带他们的事务设置。那么同一个service中，事务方法互调默认失效，原因就是**绕过了代理对象**。

**本地事务失效问题解决方法**：使用代理对象调用即可

- 引入aop starter——》aspectj
- 开启@EnableAspectJAutoProxy动态代理，所有的动态代理都是aspectj创建的，即使没有接口也可以创建动态代理
- 设置@EnableAspectJAutoProxy（exposeProxy = true）对外暴露代理对象
- 本类互调用代理对象调用

```java
	@Transactional(timeout = 30)
    public void a() {
        OrderServiceImpl orderService = (OrderServiceImpl)AopContext.currentProxy();
        orderService.b();
        orderService.c();
    }

    @Transactional(propagation = Propagation.REQUIRED, timeout = 2)
    public void b() {
        
    }
    
    @Transactional(propagation = Propagation.REQUIRES_NEW, timeout = 20)
    public void c() {
        
    }

```

## 10.Seata控制分布式事务

- 每个微服务先必须创建undo_log
- 安装事务协调器seata server
- 整合：
  - 导入依赖spring-cloud-starter-alibaba-seata  注意版本与server版本配对
  - 启动seata server
    - registry.config：注册中心配置
    - file.config
    - 大事务入口标注@GlobalTransactional 开启事务，每个远程小事务使用@Transactional 开启小事务
  - 所有想要用到分布式事务的微服务，都要使用seata DataSourceProxy代理数据源
  - 每个微服务都必须导入fille.config,registry.config
  - 配置tx-service-group
- AT模式**不适合下订单高并发模式**（2pc模式、TCC），只适用于一般分布式模式，例如保存商品信息时。
- 高并发时考虑柔性事务——最大努力通知、**可靠消息**+最终一致性方案（异步确保型）



## 11.**可靠消息**+最终一致性方案中如何保证消息可靠性-消息丢失  

### 1、消息丢失  

- 消息发送出去，由于网络问题没有抵达服务器
  - 做好容错方法（try-catch），发送消息可能会网络失败，失败后要有**重试机制**，可记录到数据库，采用定期扫描重发的方式
  - 做好**日志记录**，每个消息状态是否都被服务器收到都应该记录
  - 做好**定期重发**，如果消息没有发送成功，定期去数据库扫描未成功的消息进行重发
- 消息抵达Broker，Broker要将消息写入磁盘（持久化）才算成功。此时Broker尚未持久化完成，宕机。
  - publisher也必须加入确认**回调机制**，确认成功的消息，修改数据库消息状态。
- 自动ACK的状态下。消费者收到消息，但没来得及消息然后宕机
  - 一定开启**手动ACK**，消费成功才移除，失败或者没来得及处理就noAck并重新入队

### 2.如何保证消息可靠性-消息重复  

- 消息消费成功，事务已经提交，ack时，机器宕机。导致没有ack成功，Broker的消息重新由unack变为ready，并发送给其他消费者
- 消息消费失败，由于重试机制，自动又将消息发送出去
- 成功消费，ack时宕机，消息由unack变为ready，Broker又重新发送
  -  消费者的业务消费接口应该设计为**幂等性**的。比如扣库存有工作单的状态标志
  -  使用**防重表**（redis/mysql），发送消息每一个都有业务的唯一标识，处理过就不用处理
  -  rabbitMQ的每一个消息都有redelivered字段，可以获取**是否是被重新投递过来**的，而不是第一次投递过来的

### 3.如何保证消息可靠性-消息积压  

- 消费者宕机积压
- 消费者消费能力不足积压
- 发送者发送流量太大
  - 上线更多的消费者，进行正常消费
  - 上线专门的队列消费服务，将消息先批量取出来，记录数据库，离线慢慢处理

## 12.定时任务

- @EnableScheduling 开启定时任务（同时标注@Component）
- @Scheduled(cron = "* * * * * ?")
- 配置：TaskSchedulingAutoConfiguration   可以进行配置修改

```java
@Component
@EnableScheduling
public class HelloSchedule {

    @Scheduled(cron = "* * * * * ?")
    public void hello() {
        System.out.println("hello");
    }
}
```

- spring 中 cron表达式由6位组成，不允许第七位年
- 任务超时的情况下，定时任务会阻塞下一个定时任务，定时任务不应该阻塞
  - 让业务以异步方式自己提交到线程池
  - 设置定时任务线程池  task.scheduling.pool.size: 5  版本不同，不一定好用
  - 定时任务**异步执行**
- 解决：异步+定时任务完成定时任务不阻塞

## 13、异步任务

- @EnableAsync 开启异步任务
- @Async给希望异步执行的方法标注

```java
@Component
@EnableScheduling
@EnableAsync
public class HelloSchedule {

    @Scheduled(cron = "* * * * * ?")
    @Async
    public void hello() throws InterruptedException {
        System.out.println("hello");
        Thread.sleep(3000);
    }
}
```

- 异步任务所有服务都可以使用，不只是定时任务可以使用，默认是将任务提交给一个线程池。
- 配置：TaskExecutionAutoConfiguration  可以进行配置修改

## 14.整合sentinel

https://github.com/alibaba/Sentinel/wiki

- 导入依赖
- 下载sentinel控制台
- 配置sentinel控制台地址信息
- 控制台中配置规则，默认设置保存在内存中，重启失效

每个微服务导入包：

- spring-boot-starter-actuator  审计模块
- 配置暴露端口

自定义流控返回

- 实现接口BlockExceptionHandler

保护feign远程调用：熔断机制

- 调用方配置文件打开 Sentinel 对 Feign 的支持：`feign.sentinel.enabled=true`

- 加入 `spring-cloud-starter-openfeign` 依赖使 Sentinel starter 中的自动化配置类生效

  ```java
  @FeignClient(value = "gulimall-seckill-service", fallback = SeckillFeignServiceFallBack.class)
  public interface SeckillFeignService {
      @GetMapping("/sku/seckill/{skuId}")
      R getSkuSeckillInfo(@PathVariable("skuId") Long skuId);
  }
  ```

- 调用方手动指定降级策略，远程服务被降级，触发熔断回调方法

- 超大流量的时候，必须牺牲一些远程服务，在服务提供方指定降级策略，提供方在运行中，但不运行自己的业务逻辑，返回默认降级数据。

自定义受保护的资源：通过自定义的资源名称增加规则进行保护。https://github.com/alibaba/Sentinel/wiki/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8

- 基于try catch方式
- 基于注解方式：@SentinelResource

  都需要配置被限流以后的默认返回，url可以设置统一返回BlockExceptionHandler。

网关流控：https://github.com/alibaba/Sentinel/wiki/%E7%BD%91%E5%85%B3%E9%99%90%E6%B5%81

## 15、前后端对接注意事项

- 接口文档需要完善且描述清晰
- 对外提供的接口在文档确定后不能随意变动
- 接口与页面对应操作相对应，尽量设计复用
- 接口返回信息与页面展示信息相符合
- 时间的返回可以考虑返回字符串
- 接口需要表名参数字段传或者不传，不传极大可能为空
- 接口方法使用需要注意put/post/get与json ，queryparam，路径参数的使用
  - get不能使用 json
- 

