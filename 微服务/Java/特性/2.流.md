## 一、流的介绍

### 1.简介

流是Java API的新成员，它允许你以声明性方式处理数据集合  ，可以透明地并行处理  。

Java 8中的集合支持一个新的stream方法，它会返回一个流（接口定义在java.util.stream.Stream里）  。

### 2.流与集合的区别

**区别主要在于什么时候进行计算**。集合是一个内存中的数据结构，它包含数据结构中目前所有的值——集合中的每个元素都得先算出来才能添加到集合中。  

流则是在概念上ڌ定的数据结构（你不能添加或删除元素），其元素则是按需计算的  。

**流只能遍历一次**。遍历完之后 ，流已经被消费了，可以从原始数据源那里再获得一个新的流来重新遍历一遍 ，重复消费同一个流就会报错。

**流是内部迭代，集合是外部迭代**。

### 3.流的操作

可以连接起来的流操作称为中间操作，关闭流的操作称为终端操作。  

- 中间操作：中间操作会返回另一个流。这让多个操作可以连接起来形成一个查询，  除非流水线上触发一个终端操作，否则中间操作不会执行任何处理 。
- 终端操作：终端操作会从流的流水线生成结果。其结果是任何不是流的值，比如List、 Integer，甚至void。  

### 4.流的使用

使用流一般分三步：

- 一个数据ຸ （如集合）来执行一个查询；
- 一个中间操作，形成一条流的流水线；
- 一个终端操作，执行流水线，并能生成结果。  

流的流水线背后的理念类似于构建器模式。 在构建器模式中有一个调用链用来设置一套配置（对流来说这就是一个中间操作链），接着是调用built方法（对流来说就是终端操作）。  

## 二、使用流

### 1.筛选与切片

#### 1.谓词筛选（filter）

该操作会接受一个谓词（一个返回boolean的函数）作为参数，并返回一个包括所有符合谓词的元素的流。  

#### 2.筛选不同的元素  （distinct）

会返回一个元素各异（根据流所生成元素的hashCode和equals方法实现）的流  。

#### 3.截断流（limit）

会返回一个不超过给定长度的流。所需的长度作为参数传递给limit。  如果流是有序的，则最多会返回前n个元素。  

#### 4.跳过元素（skip）

返回一个扔掉了前n个元素的流。如果流中元素不足n个，则返回一个空流。  limit(n)和skip(n)是互补的 。



 ### 2.映射（map）

从某些对象中选择信息。  支持map方法，它会接受一个函数作为参数。这个函数会被应用到每个元素上，并将其映射成一个新的元素  。

#### 1.流的扁平化（flatMap）

各个数组并不是分别映射成一个流，而是映射成流的内容。  flatmap方法让你把一个流中的每个值都换成另一个流，然后把所有的流连接起来成为一个流。  



### 3.查找与匹配

#### 1.检查谓词是否至少一个元素（anyMatch)

流中是否有一个元素能匹配给定的谓词 .

#### 2.检查谓词是否匹配所有元素（allmatch/noneMatch）

看流中的元素是否都能匹配给定的谓词/没有任何元素与给定的谓词匹配  。

#### 3.查找元素（findAny）

将返回当前流中的任意元素 。

#### 4.查找第一个元素（findFirst ）

为什么会同时有findFirst和findAny呢？原因是并行。找到第一个元素在并行上限制更多。如果你不关心返回的元素是哪个，使用findAny，因为它在使用并行流时限制少。  



### 4.归约（reduce）

将流中所有元素反复结合起来 ，得到一个值 。这样的查询可以被称为归约查找ͺ。用函数式编程语言的术语来说，这称为折叠（ fold）  。

#### 1.元素求和

reduce接受两个参数：  

- 一个初始值，这里是0  
- 一个BinaryOperator<T>来将两个元素结合起来产生一个新值，这里我们用的是lambda (a, b) -> a + b。  

Integer类现在有了一个静态的sum方法来对两个数求和 

```java
int sum = numbers.stream().reduce(0, Integer::sum);
```

**无初始值**：reduce重载的变体，不接受初始值，但是会返回一个Optional对象 。

```java
Optional<Integer> sum = numbers.stream().reduce((a, b) -> (a + b));
```

#### 2.最大值与最小值

```java
Optional<Integer> max = numbers.stream().reduce(Integer::max);
```

#### 3.优势

相比于前面写的逐步迭代求和，使用reduce的好处在于，这里的迭代被内部迭代抽象了，这让内部实现得以选择并行执行reduce查找。  

- 无状态：诸如map或filter等操作会从流中获取每一个元素，并在输出流中得到0或1个结果，没有内部状态。
- 有状态：诸如reduce、 sum、 max等操作需要内部状态来积累结果。  不管流中有多少元素要处理，内部状态都是 有界的。



### 5.数值流

Stream API还提供了原始类型流特化，专门支持处理数值流的方法。  

#### 1.原始类型流特化

Java 8引入了三个原始类型特化流接口来解决这个问题： IntStream、 DoubleStream和LongStream，分别将流中的元素特化为int、 long和double，从而避免了暗含的装箱成本。  此外还有在必要时再把它们转换回对象流的方法。  **这些特化的原因并不在于流的复杂性，而是装箱造成的复杂性——即类似int和Integer之间的效率差异。**  

##### 1.映射到数值

将流转换为特化版本的常用方法是mapToInt、 mapToDouble和mapToLong。这些方法和前面说的map方法的工作方式一样，只是它们返回的是一个特化流，而不是Stream<T>。  

```java
int cals = menu.stream().mapToInt(Dish::getCalories).sum();
```

如果流是空的， sum默认返回0。 IntStream还支持其他的方便方法，如max、 min、 average等。  

##### 2.转换回对象流（boxed）

```java
IntStream intStream = menu.stream().mapToInt(Dish::getCalories);
Stream<Integer> stream = intStream.boxed();
```

##### 3.默认optionalInt

对于三种原始流特化，也分别有一个Optional原始类型特化版本： OptionalInt、 OptionalDouble和OptionalLong  。

#### 2.数值范围

Java 8引入了两个可以用于IntStream和LongStream的静态方法，帮助生成这种范围：range和rangeClosed。

这两个方法都是第一个参数接受起始值，第二个参数接受结束值。但range是不包含结束值的，而rangeClosed则包含结束值。  

```java
int ans = IntStream.rangeClosed(1, 100).filter(n -> n % 2 == 0).count();
```



### 6.构建流

#### 1.由值构建流

使用静态方法**Stream.of**，通过显式值创建一个流。它可以接受任意数量的参数。  使用**empty**得到一个空流  。

```java
Stream<String> stream = Stream.of("Java 8 ", "Lambdas ", "In ", "Action");
stream.map(String::toUpperCase).forEach(System.out::println);
Stream<String> stream = Stream.empty();
```

#### 2.由数组创建流

使用静态方法Arrays.stream从数组创建一个流。它接受一个数组作为参数。  

```int
int[] numbers = {2, 3, 5, 7, 11, 13};
int sum = Arrays.stream(numbers).sum();
```

#### 3.由文件生成流

Java中用于处理文件等I/O操作的NIO API（非阻塞I/O）已更新，以便利用Stream API。  java.nio.file.Files中的很多静态方法都会返回一个流。  Files.lines，它会返回一个由指定文件中的各行构成的字符串流。  

```java
// 看看一个文件中有多少各不相同的词
long uniqueWords = 0;
try(Stream<String> lines = Files.lines(Paths.get("data.txt"), Charset.defaultCharset())){
		uniqueWords = lines.flatMap(line -> Arrays.stream(line.split(" ")))
			.distinct()
			.count();
}
catch(IOException e){
}
```

#### 4.由函数生成流：创建无限流

Stream API提供了两个静态方法来从函数生成流： **Stream.iterate和Stream.generate**。  不像从ڌ定集合创建的流那样有ڌ定大小的流。由iterate和generate产生的流会用给定的函数按需创建值 。一般来说，应该使用limit(n)来对这种流加以限制，以避免打印无穷多个值  。

- **迭代：一般来说，在需要依次生成一系列值的时候应该使用iterate** 。

```java
Stream.iterate(0, n -> n + 2)
	.limit(10)
	.forEach(System.out::println);
```

- **生成：generate不是依次对每个新生成的值应用函数的**  

```java
Stream.generate(Math::random)
	.limit(5)
	.forEach(System.out::println);
```

上面是生成了5个随机值。

## 三、用流收集数据

#### 1.收集器介绍

函数式编程相对于指令式编程的一个主要优Ҹ：你只需指出希望的结果——做什么”，而不用操心执行的步骤——“如何做”。  

要是做多级分组，指令式和函数式之间的区别就会更加明显：由于需要好多层嵌套循环和条件，指令式代码很快就变得更难阅读、更难维护、更难修改。  

#####  1.收集器用作高级归约

对流调用collect方法将对流中的元素触发一个归约操作（由Collector来参数化）。  

一般来说，Collector会对元素应用一个转换函数（很多时候是不体现任何效果的恒等转换，例如toList），并将结果积累在一个数据结构中，从而产生这一过程的最终输出。  

Collectors实用类提供了很多静态工厂方法，可以方便地创建常见收集器的实例，  最直接和最常用的收集器是toList静态方法，它会把流中所有的元素收集到一个List中：  

```java
List<Transaction> transactions =transactionStream.collect(Collectors.toList());
```

##### 2.预定义收集器

也就是那些可以从Collectors类提供的工厂方法（例如groupingBy）创建的收集器。它们主要提供了三大功能：  

- 将流元素归约和汇总为一个值
- 元素分组
- 元素分区

#### 2.归约和汇总

在需要将流项目重组成集合时，一般会使用收集器（ Stream方法collect的参数）。再宽泛一点来说，但要把流中所有的项目合并成一个结果时就可以用。这个结果可以是任何类型，可以复杂如代表一棵树的多级映射，或是简单如一个整数 。

```java
// 利用counting工厂方法返回的收集器，数一数菜单里有多少种菜
long dishes = menu.stream().collect(Collectors.counting());
long dishes = menu.stream().count();
```

##### 1.查找流中的最大值和最小值

**Collectors.maxBy和Collectors.minBy**，来计算流中的最大或最小值。这两个收集器接收一个Comparator参数来比较流中的元素。  

```java
Optional<Dish> mostCalDish = menu.stream().collect(maxBy(dishComparator));
```

##### 2.汇总

Collectors类专门为汇总提供了一个工厂方法： **Collectors.summingInt。**它可接受一个把对象映射为求和所需int的函数，并返回一个收集器；该收集器在传递给普通的collect方法后即执行我们需要的汇总操作。  **Collectors.summingLong和Collectors.summingDouble**方法的作用完全一样，可以用于求和字段为long或double的情况。  还有**Collectors.averagingInt**，连同对应的**averagingLong和averagingDouble**可以计算数值的平均数  .

```java
int totalCals = menu.stream().collect(summingInt(Dish::getCalories));
```

想要得到两个或更多这样的结果，而且你希望只需一次操作就可以完成  ,使用summarizingInt工厂方法返回的收集器 ，得到总和、平均值、最大值和最小值：  

```java
IntSummaryStatistics menuStatistics = menu.stream().collect(summarizingInt(Dish::getCalories))；
```

IntSummaryStatistics的类里，它提供了方便的取值（ getter）方法来访问结果。  **summarizingLong和summarizingDouble**工厂方法有相关的LongSummaryStatistics和DoubleSummaryStatistics类 型 ， 适 用 于 收 集 的 属 性 是 原 始 类 型long或double的情况  。

##### 3.连接字符串（joining）

joining工厂方法返回的收集器会把对流中每一个对象应用toString方法得到的所有字符串连接成一个字符串。  

```java
String shortMenu = menu.stream().map(Dish::getName).collect(joining());
```

joining在内部使用了**StringBuilder**来把生成的字符串逐个追加起来。  

joining工厂方法有一个重载版本可以接受元素之间的分界符：

```java
String shortMenu = menu.stream().map(Dish::getName).collect(joining(", "));
```

##### 4.广义的归约汇总

已经讨论的所有收集器，都是一个可以用reducing工厂方法定义的归约过程的特殊情况而已。 Collectors.reducing工厂方法是所有这些特殊情况的一般化。  

```java
// 计算你菜单的总热量
int totalCalories = menu.stream().collect(reducing(0, Dish::getCalories, (i, j) -> i + j));
```

```java
// 找到最量最高的菜
Optional<Dish> mostCalorieDish =menu.stream().collect(
	reducing((d1, d2) -> d1.getCalories() > d2.getCalories() ? 
	d1 : d2)
);
```

把单参数reducing工厂方法创建的收集器看作三参数方法的特殊情况，它把流中的第一个项目作为起点，把恒等函数作为一个转换函数。  即把单参数reducing收集器传递给空流的collect方法，收集器就没有起点；  返回一个Optional<Dish>对象  。

reduce方法是在把两个值结合起来生成一个新值，它是一个不可变的归约。  collect方法的设计就是要改变容器，从而累积要输出的结果。以错误的语义使用reduce方法还会造成一个实际问题：这个归约过程不能并行工作，因为由多个线程并发修改同一个数据结构可能会破坏list本身。  

在这种情况下，如果你想要线程安全，就需要每次分配一个新的List，而对象分配影响性能。这就是collect方法适合可变容器上的归约的原因，它也适合并行操作。  

**尽可能为手头的问题探索不同的解决方案，但在通用的方案里面，始终选择最专门化的一个。**  

#### 3.分组（groupingBy ）

一个常见的数据库操作是根据一个或多个属性对集合中的项目进行分组。  

```Java
// 假设你要把菜单中的菜按照类型进行分类，有肉的放一组，有鱼的放一组，其他的都放另一组。
Map<Dish.Type, List<Dish>> dishesByType = menu.stream().collect(groupingBy(Dish::getType));
```

groupingBy方法传递了一个Function（以方法引用的形式），它提取了流中每一道Dish的Dish.Type。我们把这个Function叫作**分类函数** 。分组操作的结果是一个Map，把分组函数返回的值作为映射的键，把流中所有具有这个分类值的项目的列表作为对应的映射值。  

分类函数不一定像方法引用那样可用，因为你想用以分类的条件可能比简单的属性访问器要复杂，对应对象没有提供这个方法，无法使用方法引用，但是可以写为lambda表达式。

##### 1.多级分组（双参数版本的Collectors.groupingBy  ）

双参数版本的Collectors.groupingBy除了普通的分类函数之外，还可以接受collector类型的第二个参数。  

```java
Map<Dish.Type, Map<CaloricLevel, List<Dish>>> dishesByTypeCaloricLevel =
	menu.stream().collect(
		groupingBy(Dish::getType,
			groupingBy(dish -> {
				if (dish.getCalories() <= 400) return CaloricLevel.DIET;
				else if (dish.getCalories() <= 700) return CaloricLevel.NORMAL;
				else return CaloricLevel.FAT;
			} )
	)
);
```

两级Map：  

```
{MEAT={DIET=[chicken], NORMAL=[beef], FAT=[pork]},
FISH={DIET=[prawns], NORMAL=[salmon]},
OTHER={DIET=[rice, seasonal fruit], NORMAL=[french fries, pizza]}}
```

**这种多级分组操作可以扩展至任意层级， n级分组就会得到一个代表n级树形结构的n级Map。**  

![image-20220627172703350](https://cdn.jsdelivr.net/gh/JarvisTH/picbed/img/image-20220627172703350.png)

##### 2.按子组收集数据

**传递给第一个groupingBy的第二个收集器可以是任何类型。**

```Java
// 要数一数菜单中每类菜有多少个，可以传递counting收集器作为groupingBy收集器的第二个参数、
Map<Dish.Type, Long> typesCount = menu.stream().collect(groupingBy(Dish::getType, counting()));
```

普通的单参数groupingBy(f)（其中f是分类函数）实际上是groupingBy(f,toList())的简便写法。  

把收集器返回的结果转换为另一种类型，可以使用**Collectors.collectingAndThen**工厂方法返回的收集器 。这个工厂方法接受两个参数——要转换的收集器以及转换函数，并返回另一个收集器。  这个收集器相当于旧收集器的一个包装， collect操作的最后一步就是将返回值用转换函数做一个映射。

```Java
// 查找每个子组中བ量最高的Dish
Map<Dish.Type, Dish> mostCaloricByType = menu.stream().collect(
	groupingBy(Dish::getType, 
		collectingAndThen(maxBy(comparingInt(Dish::getCalories)), Optional::get)));
```

把好几个收集器嵌套起来很常见 ，下图展示内部工作：

![image-20220627173516687](https://cdn.jsdelivr.net/gh/JarvisTH/picbed/img/image-20220627173516687.png)

从最外层开始逐层向里，注意以下几点 ：

- 收集器用虚线表示，因此groupingBy是最外层，根据菜的类型把菜单流分组，得到三个子流。  
- groupingBy收集器包含着collectingAndThen收集器，因此分组操作得到的每个子流都用这第二个收集器做进一步归约。  
- collectingAndThen收集器又包含着第三个收集器maxBy  
- 随后由归约收集器进行子流的归约操作，然后包含它的collectingAndThen收集器会对其结果应用Optional:get转换函数。  
- 对三个子流分别执行这一过程并转换而得到的三个值，也就是各个类型中热量最高的Dish，将成为groupingBy收集器返回的Map中与各个分类键（ Dish的类型）相关联的值。  

**一般来说，通过groupingBy工厂方法的第二个参数传递的收集器将会对分到同一组中的所有流元素执行进一步归约操作。**  

- groupingBy联合使用的另一个收集器是mapping方法 ：这个方法接受两个参数：一个函数对流中的元素做变换，另一个则将变换的结果对象收集起来。其目的是在累加之前对每个输入元素应用一个映射函数，这样就可以让接受特定类型元素的收集器适应不同类型的对象。  

```java
// 对于每种类型的Dish，菜单中都有哪些CaloricLevel
Map<Dish.Type, Set<CaloricLevel>> caloricLevelsByType = menu.stream().collect(
	groupingBy(Dish::getType, mapping(
		dish -> { 
            if (dish.getCalories() <= 400) return CaloricLevel.DIET;
		   else if (dish.getCalories() <= 700) return CaloricLevel.NORMAL;
		   else return CaloricLevel.FAT; },
	toSet() ))
);

{OTHER=[DIET, NORMAL], MEAT=[DIET, NORMAL, FAT], FISH=[DIET, NORMAL]}
```

上面的方法对于对于返回的Set是什么类型并没有任何保证。  通过使用toCollection ，给它传递一个构造函数引用 要求使用想要的类型。

```java
Map<Dish.Type, Set<CaloricLevel>> caloricLevelsByType = menu.stream().collect(
	groupingBy(Dish::getType, mapping(
		dish -> { 
			if (dish.getCalories() <= 400) return CaloricLevel.DIET;
			else if (dish.getCalories() <= 700) return CaloricLevel.NORMAL;
			else return CaloricLevel.FAT; },
	toCollection(HashSet::new) ))
);
```

#### 4.分区（partitioningBy）

分区是分组的特殊情况：由一个谓词（返回一个布尔值的函数）作为分类函数，它称分区函数。  分区函数返回一个布尔值，这意味着得到的分组Map的键类型是Boolean，于是它最多可以分为两组——true是一组， false是一组。  

```java
Map<Boolean, List<Dish>> partitionedMenu = menu.stream().collect(partitioningBy(Dish::isVegetarian));

{false=[pork, beef, chicken, prawns, salmon],
true=[french fries, rice, season fruit, pizza]}
```

分区的好处在于保留了分区函数返回true或false的两套流元素列表。  

partitioningBy工厂方法有一个重载版本，可以像下面这样传递第二个收集器 ：

```java
Map<Boolean, Map<Dish.Type, List<Dish>>> vegetarianDishesByType =
	menu.stream().collect(
		partitioningBy(Dish::isVegetarian, groupingBy(Dish::getType)));

{false={FISH=[prawns, salmon], MEAT=[pork, beef, chicken]},
 true={OTHER=[french fries, rice, season fruit, pizza]}}
```

#### 5.收集器接口

```java
public interface Collector<T, A, R> {
	Supplier<A> supplier();
	BiConsumer<A, T> accumulator();
	Function<A, R> finisher();
	BinaryOperator<A> combiner();
	Set<Characteristics> characteristics();
}
```

- T是流中要收集的项目的泛型  
- A是累加器的类型，累加器是在收集过程中用于累积部分结果的对象。  
- R是收集操作得到的对象（通常但并不一定是集合）的类型。  

例如实现一个ToListCollector<T>类，将Stream<T>中的所有元素收集到一个List<T>里  。

```java
public class ToListCollector<T> implements Collector<T, List<T>, List<T>>
```



##### 1.建立新的结果容器： supplier方法  

supplier方法必须返回一个结果为空的Supplier，也就是一个无参数函数，在调用时它会创建一个空的累加器实例，供数据收集过程使用。  

```java
public Supplier<List<T>> supplier() {
	return () -> new ArrayList<T>();
}
```

##### 2.将元素添加到结果容器： accumulator方法  

当遍历到流中第n个元素时，这个函数执行时会有两个参数：保存归约结果的累加器（已收集了流中的前 n-1 个项目）， 还有第n个元素本身。  该函数将返回void，因为ጌ加器是原位更新，即函数的执行改变了它的内部状态以体现遍历的元素的效果。  

```java
public BiConsumer<List<T>, T> accumulator() {
	return (list, item) -> list.add(item);
}
```

##### 3.对结果容器应用最终转换： finisher方法  

在遍历完流后， finisher方法必须返回在累积过程的最后要调用的一个函数，以便将ጌ加器对象转换为整个集合操作的最终结果。 

```java
public Function<List<T>, List<T>> finisher() {
	return Function.identity();
}
```

##### 4.合并两个结果容器： combiner方法  

combiner方法会返回一个供归约操作使用的函数，它定义了对流的各个子部分进行并行处理时，各个子部分归约所得的累加器要如何合并。  

```java
public BinaryOperator<List<T>> combiner() {
    return (list1, list2) -> {
    	list1.addAll(list2);
    	return list1; 
    }
}
```

![image-20220627180015306](https://cdn.jsdelivr.net/gh/JarvisTH/picbed/img/image-20220627180015306.png)

- 原始流会以递归方式拆分为子流，直到定义流是否需要进一步拆分的一个条件为非（如
  果分布式工作单位太小，并行计算往往比顺序计算要慢，而且要是生成的并行任务比处
  理器内核数多很多的话就没有意义了）。
- 现在，所有的子流都可以并行处理，即对每个子流应用顺序归约算法。
- 最后，使用收集器combiner方法返回的函数，将所有的部分结果两两合并。这时会把原始流每次拆分时得到的子流对应的结果合并起来。  

![image-20220627180157645](https://cdn.jsdelivr.net/gh/JarvisTH/picbed/img/image-20220627180157645.png)

##### 5.characteristics方法  

回一个不可变的Characteristics集合，它定义了收集器的行为——尤其是关于流是否可以并行归约，以及可以使用哪些优化的提示。  

Characteristics是一个包含三个项目的枚举。

- UNORDERED——归约结果不受流中项目的遍历和累积顺序的影响。
- CONCURRENT——accumulator函数可以从多个线程同时调用，且该收集器可以并行归约流。如果收集器没有标为UNORDERED，那它仅在用于无序数据源时才可以并行归约。
- IDENTITY_FINISH——这表明完成器方法返回的函数是一个恒等函数，可以跳过。这种情况下，累加器对象将会直接用作归约过程的最终结果。这也意味着，累加器A不加检查地转换为结果R是安全的。  

```java
public class ToListCollector<T> implements Collector<T, List<T>, List<T>> {
    @Override
    public Supplier<List<T>> supplier() {
    	return ArrayList::new;
    }
    @Override
    public BiConsumer<List<T>, T> accumulator() {
   		return List::add;
    }
    @Override
    public Function<List<T>, List<T>> finisher() {
    	return Function.indentity();
    }
    @Override
    public BinaryOperator<List<T>> combiner() {
        return (list1, list2) -> {
            list1.addAll(list2);
            return list1;
        };
    }
    @Override
    public Set<Characteristics> characteristics() {
        return Collections.unmodifiableSet(EnumSet.of(
        	IDENTITY_FINISH, CONCURRENT));
    }
}
```

```java
List<Dish> dishes = menuStream.collect(new ToListCollector<Dish>());
List<Dish> dishes = menuStream.collect(toList());
```

**这个实现和标准的构造之间的其他差异在于toList是一个工厂，而ToListCollector必须用new来实例化。**  



## 四、并行处理

### 1.并行流

并行流就是一个把内容分成多个数据块，并用不同的线程分别处理每个数据块的流。  这样一来，你就可以自动把给定操作的工作负荷分配给多核处理器的所有内核，让它们都忙起来。  

**将顺序流转换为并行流**

转换成并行流，从而让前面的函数归约过程（也就是求和）并行运行——对顺序流调用parallel方法  

```java
Stream.iterate(1L, i -> i + 1)
	.limit(n)
	.parallel()
	.reduce(0L, Long::sum);
```

在现实中，对顺序流调用parallel方法并不意味着流本身有任何实际的变化。它在内部实际上就是设了一个boolean标志，表示你想让调用parallel之后进行的所有操作都并行执行。  

只需要对并行流调用**sequential方法**就可以把它变成顺序流。  

把这两个方法结合起来，并不能更细化地控制在遍历流时哪些操作要并行执行 ，因为最后一次parallel或sequential调用会影响整个流水线  。

并行流内部使用了默认的ForkJoinPool，它默认的线程数量就是你的处理器数量，可以通过系统属性java.util.concurrent.ForkJoinPool.common.parallelism来改变线程的大小 ：

```java
System.setProperty("java.util.concurrent.ForkJoinPool.common.parallelism","12");
```

这是一个全局设置，因此它将影响代码中所有的并行流。反过来说，暂时还无法专为౼个并行流指定这个值。  解决方法 利用CompletableFuture + 指定线程池。

**使用正确的数据结构然后使其并行工作能够保证最佳的性能**  。

并行化并不是没有代价的，并行化过程本身需要对流做递归划分，把每个子流的归纳操作分配到不同的线程，然后把这些操作的结果合并成一个值， 在多个内核之间移动动数据的代价也大 ，所以并行化之前要确认操作并行后可以加速。

注意点：

- 把顺序流转成并行流轻而易举 ，并行流有时候会和你的直觉不一致，所以在考虑选择顺序流还是并行流时，第一个也是最重要的建议就是用适当的基准来检查其性能 。
- 自动装箱和拆箱操作会大大降低性能。 Java 8中有原始类型流（ IntStream、LongStream、 DoubleStream）来避免这种操作，但ї有可能都应该用这些流。  
- 有些操作本身在并行流上的性能就比顺序流差
- 考虑流的操作流水线的总计算成本
- 并行处理少数几个元素的好处比不上并行化造成的额外开销
- 要考虑流背后的数据结构是否易于分解  
- 要考虑终端操作中合并步骤的代价是大是小  

### 2.Fork/Join框架

以递归方式将可以并行的任务划分成更小的任务，然后将每个子任务的结果合并起来生成整体结果。  

ExecutorService接口的一个实现，它把子任务分配给线程池（称为ForkJoinPool）中的工作线程。  要把任务提交到这个池，必须创建RecursiveTask<R>的一个子类，其中R是并行化任务（以及所有子任务）产生的结果类型，或者如果任务不返回结果，则是RecursiveAction类型 。要定义RecursiveTask， 只需实现它唯一的抽象方法compute：  

```java
protected abstract R compute();
```

这个方法同时定义了将任务划分成子任务的逻辑，以及无法再拆分或不方便再拆分时，生成单个子任务结果的逻辑。  

> if (任务足够小或不可分) {
> 	顺序计算该任务
> } else {
> 	将任务分成两个子任务
> 	递归调用本方法，拆分每个子任务，等待所有子任务完成
> 	合并每个子任务的结果
> }  

一般来说并没有确切的标准决定一个任务是否应该再拆分，但有几种试探方法可以帮助你做出这一决定。  

示例：

```java
public class ForkJoinSumCalculator
        extends java.util.concurrent.RecursiveTask<Long> { // 继承RecursiveTask来创建可以用于fork/join框架的任务
    private final long[] numbers;	// 要求和的数组
    private final int start;	// 子任务处理的数组的起始/终止位置
    private final int end;
    public static final long THRESHOLD = 10_000;  // 不再将任务分解为子任务的数组大小

    // 公共构造函数用于创建主任务
    public ForkJoinSumCalculator(long[] numbers) {
        this(numbers, 0, numbers.length);
    }

    // 私有构造函数用于递归方式为主任务创建子任务
    private ForkJoinSumCalculator(long[] numbers, int start, int end) {
        this.numbers = numbers;
        this.start = start;
        this.end = end;
    }

    @Override
    protected Long compute() {
        // 负责求和的部分的大小
        int length = end - start;
        if (length <= THRESHOLD) {
            // 顺序计算结果
            return computeSequentially();
        }
        // 创建子任务为数组的前一半求和
        ForkJoinSumCalculator leftTask =
                new ForkJoinSumCalculator(numbers, start, start + length / 2);
        leftTask.fork();
         // 创建子任务为数组的后一半求和
        ForkJoinSumCalculator rightTask =
                new ForkJoinSumCalculator(numbers, start + length / 2, end);
        Long rightResult = rightTask.compute();
        // 读取第一个子任务的结果，如果未完成就等待
        Long leftResult = leftTask.join();
        return leftResult + rightResult;
    }

    // 不可再分时计算方式
    private long computeSequentially() {
        long sum = 0;
        for (int i = start; i < end; i++) {
            {
                sum += numbers[i];
            }
            return sum;
        }
    }
```

编写一个方法来并行对前n个自然数求和：

```java
public static long forkJoinSum(long n) {
	long[] numbers = LongStream.rangeClosed(1, n).toArray();
	ForkJoinTask<Long> task = new ForkJoinSumCalculator(numbers);
	return new ForkJoinPool().invoke(task);
}
```

当把ForkJoinSumCalculator任务传给ForkJoinPool时，这个任务就由池中的一个线程执行，这个线程会调用任务的compute方法。该方法会检查任务是否小到足以顺序执行，如果不够小则会把要求和的数组分成两半，分给两个新的ForkJoinSumCalculator，而它们也由
ForkJoinPool安排执行。  

Fork/Join框架使用注意点：

- 对一个任务调用join方法会阻塞调用方，直到该任务做出结果。因此，有必要在两个子任务的计算都开始之后再调用它。  
- 不应该在RecursiveTask内部使用ForkJoinPool的invoke方法，应该始终直接调用compute或fork方法，只有顺序代码才应该用invoke来启动并行计算 。
- 对子任务调用fork方法可以把它排进ForkJoinPool 
- 一个任务可以分解成多个独立的子任务，才能让性能在并行化时有所提升



**工作窃取**

分出大量的小任务一般来说都是一个好的选择，应该让每个任务都用完全相同的时间完成，让所有的CPU内核都同样繁忙。

工作窃取算法用于在池中的工作线程之间重新分配和平衡任务。 每个线程都为分配给它的任务保存一个Ԥ向链式队列，每完成一个任务，就会从队列头上取出下一个任务开始执行。基于前面所述的原因，某个线程可能很早完成了分配给它的所有任务，也就是它的队列已经
空了，而其他的线程还很忙。这时，这个线程并没有闲下来，而是随机选了一个别的线程，从队列的尾部偷走一个任务。这个过程一直继续下去，直到所有的任务都执行完毕，所有的队列都清空。  

### 3.Spliterator  

```java
public interface Spliterator<T> {
	boolean tryAdvance(Consumer<? super T> action);
	Spliterator<T> trySplit();
	long estimateSize();
	int characteristics();
}
```

- T是Spliterator遍历的元素的类型。 

- tryAdvance方法的行为类似于普通的Iterator，因为它会按顺序一个一个使用Spliterator中的元素，并且如果还有其他元素要遍历就返回true。  
- trySplit是专为Spliterator接口设计的，因为它可以把一些元素划出去分给第二个Spliterator（由该方法返回），让它们两个并行处理。  
- estimateSize方法估计还қ下多少元素要遍历，因为即使不那么准确，能快速算出来是一个值也有助于让拆分均匀一点。  

将Stream拆分成多个部分的算法是一个递归过程 ：

- 第一步是对第一个Spliterator调用trySplit，生成第二个Spliterator。
- 第二步对这两个Spliterator调用trysplit，这样总共就有了四个Spliterator。
- 这个框架不断对Spliterator调用trySplit直到它返回null，表明它处理的数据结构不能再分Ҟ，如第三步所示。
- 最后，这个递归拆分过程到第四步就终止了，这时所有的Spliterator在调用trySplit时都返回了null。  

![image-20230313220745696](../../../../../picbed/store/picbed/img/image-20230313220745696.png)

![image-20230313220822149](../../../../../picbed/store/picbed/img/image-20230313220822149.png)
