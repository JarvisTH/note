## =；一、五个简单TCP示例

### 1.discard

简单长连接TCP应用层协议，只关注消息/数据到达事件。

### 2.daytime

短连接协议，发送完当前时间后，服务端主动断开连接。只关注连接已建立事件。

### 3.time

返回一个32bit整数，表示从1970-01-01 00：00：00Z到现在的秒数。只关注连接已建立事件。

### 4.echo

双向协议，服务端将客户端发来的消息返回回去，只关注消息/数据到达事件。

漏洞：客户端只发不收数据，可能撑爆服务端内存，解决方法可以参考chargen协议或者发送缓冲区到一定大小时主动断开。

### 5.chargen

只发数据，不接收数据。且发送速度不能快过客户端接收速度。只关注消息/数据到达事件。



## 二、文件传输

在非阻塞网络编程中，发送消息通常由网络库完成。muduo重载了三个send函数，使用TcpConnection::send函数注意点：

- send返回类型是void。
- send是非阻塞的。
- send是线程安全的。多线程发送时不保证顺序性。
- send（message，len）可以发送任意字节序列。
- send（message）可以发送string、const char*。StringPiece是Google专门用来传递字符串的class，这样程序不必为string、char* 重载两份
- send（buffer*），以指针为参数，因为函数可能用Buffer::swap交换数据，避免内存拷贝。

文件发送小工具：指定发送的文件，监听2021端口，有连接进来就发送完整文件。

健壮性要求：支持上万并发客户连接；内存消耗只与并发连接数有关，与文件大小无关；连接可以在任何时候端口，程序不会内存泄漏或者崩溃。

- 版本一：一次性把文件读入内存，一次性调用send发送完毕。消耗内存与文件大小成正比。
- 版本二：分块发送文件，减少内存使用，调用写完回调函数。每次建立连接都会重新打开文件，文件描述符数量会翻倍。如果客户端只发起连接，不接收数据，服务端文件描述符可能耗尽或者占用很多内存。可以限制服务端最大并发连接数、踢掉空闲连接方式解决。
- 版本三：分块发送文件，使用share_ptr管理file*，避免手动调用flcose。将资源管理转为对象生命周期管理，即RAII。



## 三、Boot.Asio聊天服务器

### 1.TCP分包

TCP协议做应用层分包是网络编程基本需求。分包是指发生在一个消息或者一帧数据时，处理后能够让对方识别出一个个消息。

对于短链接的TCP服务，分包不是问题。

对于长连接服务，分包有四种方法：

- 消息长度固定。
- 使用特殊字符或者字符串作为消息边界。
- 每条消息头部加一个长度字段。
- 利用消息格式分包。



聊天服务是基于TCP应用层广播协议，服务端将消息发送给每个连接的客户端。聊天服务特点是连接间数据有交流。这对管理连接提出更高要求：如何同时处理多个连接？如何防止串话（b端口连接而新建的c连接恰好复用b的文件描述符）？

### 2.消息格式

消息是一条字符串，每条消息有4字节头部，以网络序存放字符串长度。消息间没有间隙，字符串也不要求以/0结尾。

- 打包消息

  ![image-20211230234147073](https://cdn.jsdelivr.net/gh/JarvisTH/picbed/img/20211230234155.png)

- 分包消息

  ![image-20211230234205533](https://cdn.jsdelivr.net/gh/JarvisTH/picbed/img/20211230234207.png)

  32行在某些不支持非对齐内存访问体系结构上任意core dump，读取消息长度改用Buffer::peekInt32。decode时要在收到完整消息后在retriveve整条消息，除非对方使用复杂状态机解码。

### 3.编解码器LengthHeaderCodec

muduo的接收缓冲区不能设置回调函数的触发条件。加一个间接层可以解决这个问题，只关心消息达到，而不是数据到达。

![image-20211230234938264](https://cdn.jsdelivr.net/gh/JarvisTH/picbed/img/20211230234939.png)

用户代码不必关系分包操作，具体调用时序如下：

![image-20211230235204633](https://cdn.jsdelivr.net/gh/JarvisTH/picbed/img/20211230235205.png)

如果编程语言相同，客户端和服务器可以共用一个codec，方便又降低误解。

### 4.服务端实现

chatServer定义了connecttions_存放目前已连接客户，收到消息后遍历容器，广播消息。

代码中将LengthHeaderMessage::OnMessage注册给server_，然后向codec_注册了chatServer::onStringMessage，就是让codec解析消息，然后把完整消息回调给chatServer。这个就是前面说的间接层。

### 5.客户端实现

构造函数里注册回调函数，使用lengthHeaderCodec作为中间层，负责打包、分包。收到消息打印到屏幕使用printf是线程安全的，而cout不是线程安全的。

## 四、muduo Buffer类设计与使用

### 1.muduo的IO模型

event loop是non-blocking网络编程的核心，总是与IO multiplexing一起使用：

- 不用轮询去检测某个non-blocking IO操作是否完成，浪费CPU
- IO multiyplexing一般不和blocking io一起使用，因为blocking IO会阻塞线程，这样线程没法处理其他socket上的IO 事件。

### 2.为什么non-blocking网络编程中应用层buffer是必须的?

non-blocking IO核心是避免阻塞在read/write或其他IO系统调用上，最大限度复用thread-of-control，让一个线程服务多个socket连接。IO线程只能阻塞在IO multiplexing上，如select/poll/epoll_wait。这样，缓冲区是必须的，每个TCP socket都有stateful的input buffer和output buffer。

- output buffer

场景：程序通过TCP发送100kb数据，write调用中只接受80kb，剩下20kb由网络库接管，保存至TCP connection中的output buffer中，注册POLLOUT事件，socker变得可写时立刻发送数据。如果写完了20kb，网络库一个停止关注POLLOUT事件。加入程序又写入50kb，此时ouput buffer还有20kb，应该把这50kb数据append到20kb后，一起发送。

如果output buffer还有数据，而程序想关闭连接，此时不能立刻关闭连接，要等数据发送完毕，

所以，要让程序不在write上阻塞，需要给每个TVP配置一个output buffer。

- input buffer

TCP连接是无边界的字节流协议，接收方必须处理收到数据不完整和一次收到两条消息的数据等情况。一般而言，长度为n字节的消息分块可能性有2的（n减一）次方种。

网络库在处理可读消息时，必须一次性把socket数据读完，否则触发反复POLLIN事件，造成busy-loop。

input buffer必然面临收到数据不完整情况，收到的数据先存入intput buffer，等构成完整消息再通知业务处理逻辑，通常是codec职责。muduo EventLoop采用的是epoll（4）level trigger，原因是：

- 兼容传统poll（2）。
- level tigger编程更容易；
- 读写时不必等会出现EACAIN。

### 3.Buffer的功能需求

